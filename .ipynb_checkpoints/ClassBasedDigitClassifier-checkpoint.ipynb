{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d63ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acd65f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = {\n",
    "                'digit_0' : 0,\n",
    "                'digit_1' : 1,\n",
    "                'digit_2' : 2,\n",
    "                'digit_3' : 3,\n",
    "                'digit_4' : 4,\n",
    "                'digit_5' : 5,\n",
    "                'digit_6' : 6,\n",
    "                'digit_7' : 7,\n",
    "                'digit_8' : 8,\n",
    "                'digit_9' : 9,\n",
    "}\n",
    "train_data = pd.read_csv('./dataset/digit_all_augmented.csv')\n",
    "test_data  = pd.read_csv('./dataset/test_digits_data.csv')\n",
    "X_train = train_data.iloc[:, 1:-1].values\n",
    "y_train = train_data.iloc[:, -1]\n",
    "y_train = y_train.replace(charset)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61885a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "mm = StandardScaler()\n",
    "X_train = mm.fit_transform(X_train)\n",
    "# X_dev   = mm.fit_transform(X_dev)\n",
    "X_test = mm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd5185ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mm,open('scaler_norm.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f76d683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\t\t\t Before Processing\t After Processing\n",
      "=================================================================\n",
      "Training Set Images:\t(85000, 1026)\t\t(68000, 1024)\n",
      "Training Set Labels:\t(85000,)\t\t(68000,)\n",
      "Test Set Images:\t(3000, 1025)\t\t(17000, 1024)\n",
      "Test Set Labels:\t(3000,)\t\t\t(3000,)\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Data\\t\\t\\t\",\"Before Processing\\t\",\"After Processing\")\n",
    "print(\"=================================================================\")\n",
    "print(\"Training Set Images:\\t\" + str(train_data.shape)+\"\\t\\t\"+ str(X_train.shape))\n",
    "print(\"Training Set Labels:\\t\" + str(train_data.iloc[:, -1].shape)+\"\\t\\t\"+ str(y_train.shape))\n",
    "# print(\"Dev Set Images:\\t\\t\" + str(X_dev.shape)+\"\\t\\t\"+ str(X_dev.shape))\n",
    "# print(\"Dev Set Labels:\\t\\t\" + str(y_dev.shape)+\"\\t\\t\\t\"+ str(y_dev.shape))\n",
    "print(\"Test Set Images:\\t\" + str(test_data.shape)+\"\\t\\t\"+ str(X_test.shape))\n",
    "print(\"Test Set Labels:\\t\" + str(test_data.iloc[:, -1].shape)+\"\\t\\t\\t\"+ str(test_data.iloc[:, -1].shape))\n",
    "print(\"=================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a695ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier:\n",
    "    def __init__(self, n_inputs, n_neurons = [32,32,10]):\n",
    "        np.random.seed(42)\n",
    "    # We have done here n_inputs/n_neurons instead of n_neurons/n_inputs to prevent the Transpose everytime\n",
    "        self.weights1 = 0.01 * np.random.randn(n_inputs, n_neurons[0]) # The input shape and no of neurons you want to have in the layer\n",
    "        self.biases1 =  0.01 * np.random.randn(1, n_neurons[0])\n",
    "        self.weights2 = 0.01 *np.random.randn(n_neurons[0], n_neurons[1]) # The input shape and no of neurons you want to have in the layer\n",
    "        self.biases2 = 0.01 * np.random.randn(1, n_neurons[1])\n",
    "        self.weights3 = 0.01 * np.random.randn(n_neurons[1], n_neurons[2])\n",
    "        self.biases3 = 0.01 * np.random.randn(1, n_neurons[2])\n",
    "        self.output1 = None\n",
    "        self.output2 = None\n",
    "        self.output3 = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        # activatied outputs\n",
    "        self.output1_act = None\n",
    "        self.output2_act = None\n",
    "        self.output3_act = None\n",
    "    def forward(self, inputs, weights, biases):\n",
    "        \"\"\" The dot product of the input - weights - Biases (y = Wx + b) \"\"\"\n",
    "        output = np.dot(inputs, weights) + biases\n",
    "        if(np.isnan(np.sum(output))):\n",
    "            raise Exception(\"NaN values present in FW pass\")\n",
    "        elif(np.isinf(np.sum(output))):\n",
    "            raise Exception(\"INF values present in FW Pass\")\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def ReLU(self, inputs):\n",
    "        \"\"\" Rectified Linear Activation Function \"\"\"\n",
    "        output = np.maximum(0, inputs)\n",
    "        return output\n",
    "    \n",
    "    def Softmax(self, inputs):\n",
    "    # subtract largest value to prevent overflow\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                            keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        if(np.isnan(np.sum(probabilities))):\n",
    "            raise Exception(\"NaN values present in Softmax For\")\n",
    "        elif(np.isinf(np.sum(probabilities))):\n",
    "            raise Exception(\"INF values present in Softmax For\")\n",
    "        \n",
    "        return probabilities\n",
    "        \n",
    "    def categorical_cross_entropy(self,y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-6, 1-1e-6)\n",
    "        # Handling if labels are 1D \n",
    "        correct_confidences = None\n",
    "        if len(y_true.shape) == 1:\n",
    "#             print(y_pred_clipped[range(samples), :].shape)\n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "        elif len(y_true.shape) ==2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true, axis =1)\n",
    "        else:\n",
    "            raise Exception(\"Sorry, no numbers below zero\")\n",
    "        \n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "#         print(negative_log_likelihoods.shape)\n",
    "        return negative_log_likelihoods \n",
    "    \n",
    "    def linear_backward(self,inputs, weights, dvalues):\n",
    "        self.dweights_linear = np.dot(inputs.T, dvalues)\n",
    "        self.dbiases_linear = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dinput_linear = np.dot(dvalues, weights.T)\n",
    "        \n",
    "        if(np.isnan(np.sum(self.dweights_linear))):\n",
    "            raise Exception(\"NaN values present in Linear Back\")\n",
    "        elif(np.isinf(np.sum(self.dweights_linear))):\n",
    "            raise Exception(\"INF values present in Linear BAck\")\n",
    "        \n",
    "        \n",
    "        return self.dweights_linear, self.dinput_linear\n",
    "    \n",
    "    def linear_backward_with_l2(self,inputs, weights, dvalues, lambd = 0.5):\n",
    "        \"\"\"  \"\"\"\n",
    "        m = inputs.shape[1]\n",
    "        self.dweights_linear = np.dot(inputs.T, dvalues) + (lambd*weights)/m\n",
    "        self.dbiases_linear = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dinput_linear = np.dot(dvalues, weights.T) \n",
    "        \n",
    "        if(np.isnan(np.sum(self.dweights_linear))):\n",
    "            raise Exception(\"NaN values present in Linear Back\")\n",
    "        elif(np.isinf(np.sum(self.dweights_linear))):\n",
    "            raise Exception(\"INF values present in Linear BAck\")\n",
    "        \n",
    "        \n",
    "        return self.dweights_linear, self.dinput_linear\n",
    "    \n",
    "    def softmax_backward(self,dA, Z):\n",
    "        \"\"\"Compute backward pass for softmax activation\"\"\"\n",
    "        softmax_output = self.Softmax(Z) \n",
    "        return softmax_output * (1 - softmax_output) * dA\n",
    "\n",
    "    def ReLU_backward(self,dA, Z):\n",
    "        \n",
    "        dZ = np.array(dA, copy=True)\n",
    "        dZ[Z <= 0] = 0\n",
    "        if(np.isnan(np.sum(dZ))):\n",
    "            raise Exception(\"NaN values present in RELU Back\")\n",
    "        elif(np.isinf(np.sum(dZ))):\n",
    "            raise Exception(\"INF values present in RELU BAck\")\n",
    "        return dZ\n",
    "        \n",
    "    def categorical_cross_entropy_backward(self, dvalues, y_true):\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs_loss = self.dinputs / samples\n",
    "        if(np.isnan(np.sum(self.dinputs))):\n",
    "            raise Exception(\"NaN values present in Softmax Back\")\n",
    "        elif(np.isinf(np.sum(self.dinputs))):\n",
    "            raise Exception(\"INF values present in Softmax_back\")\n",
    "        return self.dinputs\n",
    "    \n",
    "    def softmax_categorical_cross_entropy_combined_backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        #handling Ohe values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs_combined = dvalues.copy()\n",
    "        # Calculate gradient\n",
    "        self.dinputs_combined[range(samples), y_true] -= 1\n",
    "        # Normalize gradient\n",
    "        self.dinputs_combined = self.dinputs_combined / samples\n",
    "        if(np.isnan(np.sum(self.dinputs_combined))):\n",
    "            raise Exception(\"NaN values present in Softmax Back\")\n",
    "        elif(np.isinf(np.sum(self.dinputs_combined))):\n",
    "            raise Exception(\"INF values present in Softmax_back\")\n",
    "       \n",
    "        return self.dinputs_combined\n",
    "        \n",
    "    \n",
    "    def compute_loss(self,y_pred, y_true):\n",
    "        sample_losses = self.categorical_cross_entropy(y_pred, y_true)\n",
    "        loss = np.mean(sample_losses)\n",
    "        return loss\n",
    "    \n",
    "    def compute_loss_with_l2(self,y_pred, y_true, lambd = 0.5):\n",
    "        m = 10\n",
    "        sample_losses = self.categorical_cross_entropy(y_pred, y_true)\n",
    "        L2_regularization_cost = (lambd/(2*m))*(np.sum(np.square(self.weights1) + np.sum(np.square(self.weights2) + np.sum(np.square(self.weights3)))))\n",
    "        loss = np.mean(sample_losses) \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "        self.X = X\n",
    "        self.output1     = self.forward(self.X, self.weights1, self.biases1)\n",
    "        self.output1_act = self.ReLU(self.output1)\n",
    "        self.output2     = self.forward(self.output1_act, self.weights2, self.biases2)\n",
    "        self.output2_act = self.ReLU(self.output2)\n",
    "        self.output3     = self.forward(self.output2_act, self.weights3, self.biases3)\n",
    "        self.output3_act = self.Softmax(self.output3)\n",
    "#         print(\"Softmax SUM\", np.sum(self.output3_act, axis = 1))\n",
    "        if(np.isnan(np.sum(self.output3_act))):\n",
    "            raise Exception(\"NaN values present in data\")\n",
    "        elif(np.isinf(np.sum(self.output3_act))):\n",
    "            raise Exception(\"INF values present in data\")\n",
    "        \n",
    "        \n",
    "    def check_inf(self):\n",
    "        check_weights = np.any(np.isinf(self.weights1)) or np.any(np.isinf(self.weights2)) or np.any(np.isinf(self.weights3))\n",
    "        check_bias    = np.any(np.isinf(self.biases1)) or np.any(np.isinf(self.biases2)) or np.any(np.isinf(self.biases3))\n",
    "        return (check_weights or check_bias)\n",
    "    \n",
    "    def backward_pass(self, y, learning_rate= 0.1, iteration = 10000):\n",
    "        self.y = y\n",
    "        for i in range(iteration):\n",
    "            self.forward_pass(self.X)\n",
    "            predictions = np.argmax(self.output3_act, axis=1)\n",
    "            \n",
    "            \n",
    "            gradient_output3_act                  = self.softmax_categorical_cross_entropy_combined_backward(self.output3_act, self.y)\n",
    "            gradient_output3, gradient_input3     = self.linear_backward(self.output2,self.weights3,gradient_output3_act)\n",
    "            gradient_output2_act                  = self.ReLU_backward(gradient_input3, self.output2)\n",
    "            gradient_output2, gradient_input2     = self.linear_backward(self.output1, self.weights2, gradient_output2_act)\n",
    "            gradient_output1_act                  = self.ReLU_backward(gradient_input2, self.output1)\n",
    "            gradient_output1, gradient_input1     = self.linear_backward(self.X, self.weights1, gradient_output1_act)\n",
    "            \n",
    "            self.weights3  = self.weights3 - learning_rate * gradient_output3\n",
    "            self.weights2  = self.weights2 - learning_rate * gradient_output2\n",
    "            self.weights1  = self.weights1 - learning_rate * gradient_output1\n",
    "            assert np.sum(gradient_output1) != np.nan, \"The gradient has nan\"\n",
    "            assert np.sum(gradient_output1) != np.inf, \"The gradient has inf\"\n",
    "            if i%100 == 0:\n",
    "\n",
    "                loss = self.compute_loss(self.output3_act, y)\n",
    "                self.accuracy = np.mean(predictions==self.y)\n",
    "                if(self.accuracy > 99.0):\n",
    "                    break\n",
    "                print(f'Loss after a iteration {i}:{loss} || Accuracy: {self.accuracy * 100}')\n",
    "                \n",
    "    def backward_pass_with_l2(self, y, learning_rate= 0.01, iteration = 10000):\n",
    "        self.y = y\n",
    "        self.loss_list = []\n",
    "        self.acc_list = []\n",
    "        for i in range(iteration):\n",
    "            self.forward_pass(self.X)\n",
    "            predictions = np.argmax(self.output3_act, axis=1)\n",
    "            \n",
    "            \n",
    "            gradient_output3_act                  = self.softmax_categorical_cross_entropy_combined_backward(self.output3_act, self.y)\n",
    "#             print(gradient_output3_act)\n",
    "            gradient_output3, gradient_input3     = self.linear_backward_with_l2(self.output2,self.weights3,gradient_output3_act)\n",
    "            gradient_output2_act                  = self.ReLU_backward(gradient_input3, self.output2)\n",
    "            gradient_output2, gradient_input2     = self.linear_backward_with_l2(self.output1, self.weights2, gradient_output2_act)\n",
    "            gradient_output1_act                  = self.ReLU_backward(gradient_input2, self.output1)\n",
    "            gradient_output1, gradient_input1     = self.linear_backward_with_l2(self.X, self.weights1, gradient_output1_act)\n",
    "            \n",
    "            self.weights3  = self.weights3 - learning_rate * gradient_output3\n",
    "            self.weights2  = self.weights2 - learning_rate * gradient_output2\n",
    "            self.weights1  = self.weights1 - learning_rate * gradient_output1\n",
    "            assert np.sum(gradient_output1) != np.nan, \"The gradient has nan\"\n",
    "            assert np.sum(gradient_output1) != np.inf, \"The gradient has inf\"\n",
    "            loss = self.compute_loss_with_l2(self.output3_act, y)\n",
    "            self.accuracy = np.mean(predictions==self.y)\n",
    "            if i%100 == 0:\n",
    "                self.loss_list.append(loss)\n",
    "                self.acc_list.append(self.accuracy)\n",
    "                if(self.accuracy > .99):\n",
    "                    break\n",
    "                print(f'Loss after a iteration {i}:{loss} || Accuracy: {self.accuracy * 100}')\n",
    "        plt.plot(self.loss_list)\n",
    "        plt.title(\"Training loss of the model\")\n",
    "    def load_model(self, weights, biases = None):\n",
    "        self.weights1 = weights['1']\n",
    "        self.weights2 = weights['2']\n",
    "        self.weights3 = weights['3']\n",
    "        \n",
    "        self.biases1 = weights['b1']\n",
    "        self.biases2 = weights['b2']\n",
    "        self.biases3 = weights['b3']\n",
    "    \n",
    "    def save_model(self, filename = f'model.pkl'):\n",
    "        from datetime import date\n",
    "\n",
    "        today = date.today()\n",
    "\n",
    "        filename = f'model_{self.accuracy}-{today}.pkl'\n",
    "        weights = {\n",
    "                    '1': self.weights1, '2': self.weights2, '3': self.weights3, \n",
    "                    'b1':self.biases1,'b2':self.biases2,'b3':self.biases3\n",
    "        }\n",
    "        pickle.dump(weights, open(filename, 'wb'))\n",
    "        \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        output1     = self.forward(X_test, self.weights1, self.biases1)\n",
    "        output1_act = self.ReLU(output1)\n",
    "        output2     = self.forward(output1_act, self.weights2, self.biases2)\n",
    "        output2_act = self.ReLU(output2)\n",
    "        output3     = self.forward(output2_act, self.weights3, self.biases3)\n",
    "        output3_act = self.Softmax(output3)\n",
    "        print(output3_act)\n",
    "        prediction, prediction_prob = np.argmax(output3_act, axis=1), np.max(output3_act, axis=1)\n",
    "        return prediction, output3_act\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f16fc187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after a iteration 0:2.3026371156155427 || Accuracy: 10.023529411764706\n",
      "Loss after a iteration 100:2.3025795454246407 || Accuracy: 10.023529411764706\n",
      "Loss after a iteration 200:2.3025245573767203 || Accuracy: 10.023529411764706\n",
      "Loss after a iteration 300:2.302470486840315 || Accuracy: 10.023529411764706\n",
      "Loss after a iteration 400:2.3024155915055884 || Accuracy: 10.023529411764706\n",
      "Loss after a iteration 500:2.3023582614526097 || Accuracy: 10.023529411764706\n",
      "Loss after a iteration 600:2.302296748196491 || Accuracy: 10.023529411764706\n",
      "Loss after a iteration 700:2.3022291381068447 || Accuracy: 10.023529411764706\n",
      "Loss after a iteration 800:2.302152855749303 || Accuracy: 10.023529411764706\n",
      "Loss after a iteration 900:2.302064871663769 || Accuracy: 10.023529411764706\n",
      "Loss after a iteration 1000:2.3019608725506444 || Accuracy: 10.035294117647059\n",
      "Loss after a iteration 1100:2.3018348748140083 || Accuracy: 10.100000000000001\n",
      "Loss after a iteration 1200:2.301678415782322 || Accuracy: 10.188235294117646\n",
      "Loss after a iteration 1300:2.3014787436299944 || Accuracy: 10.494117647058824\n",
      "Loss after a iteration 1400:2.3012166599207555 || Accuracy: 11.111764705882353\n",
      "Loss after a iteration 1500:2.300862097534179 || Accuracy: 11.935294117647059\n",
      "Loss after a iteration 1600:2.300364093301747 || Accuracy: 13.088235294117649\n",
      "Loss after a iteration 1700:2.299631233853711 || Accuracy: 14.629411764705882\n",
      "Loss after a iteration 1800:2.298485703881949 || Accuracy: 17.794117647058822\n",
      "Loss after a iteration 1900:2.2965542563618095 || Accuracy: 21.711764705882352\n",
      "Loss after a iteration 2000:2.2929475499836105 || Accuracy: 22.93529411764706\n",
      "Loss after a iteration 2100:2.2852436663512288 || Accuracy: 18.18235294117647\n",
      "Loss after a iteration 2200:2.265920457960266 || Accuracy: 14.641176470588235\n",
      "Loss after a iteration 2300:2.217279102658645 || Accuracy: 14.33529411764706\n",
      "Loss after a iteration 2400:2.1579754287104684 || Accuracy: 16.141176470588235\n",
      "Loss after a iteration 2500:2.10772950820263 || Accuracy: 18.41176470588235\n",
      "Loss after a iteration 2600:2.0527029513508936 || Accuracy: 18.770588235294117\n",
      "Loss after a iteration 2700:1.9834315077623375 || Accuracy: 24.96470588235294\n",
      "Loss after a iteration 2800:1.8735816448101972 || Accuracy: 26.81764705882353\n",
      "Loss after a iteration 2900:1.7386120795409299 || Accuracy: 27.458823529411763\n",
      "Loss after a iteration 3000:1.6343430933475804 || Accuracy: 30.158823529411766\n",
      "Loss after a iteration 3100:1.5544504598711382 || Accuracy: 38.42941176470588\n",
      "Loss after a iteration 3200:1.477579432849664 || Accuracy: 41.18235294117647\n",
      "Loss after a iteration 3300:1.4000253152337427 || Accuracy: 47.45882352941177\n",
      "Loss after a iteration 3400:1.3272856047209056 || Accuracy: 51.78823529411765\n",
      "Loss after a iteration 3500:1.2570891846745627 || Accuracy: 56.54705882352942\n",
      "Loss after a iteration 3600:1.1872512772524617 || Accuracy: 60.182352941176475\n",
      "Loss after a iteration 3700:1.12115916549735 || Accuracy: 62.15882352941177\n",
      "Loss after a iteration 3800:1.0639101558838517 || Accuracy: 63.617647058823536\n",
      "Loss after a iteration 3900:1.0153171372831664 || Accuracy: 64.70588235294117\n",
      "Loss after a iteration 4000:0.9736356457548904 || Accuracy: 65.64705882352942\n",
      "Loss after a iteration 4100:0.9372107192325355 || Accuracy: 66.43529411764706\n",
      "Loss after a iteration 4200:0.9046095428431247 || Accuracy: 67.64705882352942\n",
      "Loss after a iteration 4300:0.875077947010554 || Accuracy: 68.82941176470588\n",
      "Loss after a iteration 4400:0.8478305975282983 || Accuracy: 69.85294117647058\n",
      "Loss after a iteration 4500:0.822013693233392 || Accuracy: 70.87058823529412\n",
      "Loss after a iteration 4600:0.7969862339224381 || Accuracy: 71.60588235294118\n",
      "Loss after a iteration 4700:0.7727402070750222 || Accuracy: 72.55294117647058\n",
      "Loss after a iteration 4800:0.7494636452076764 || Accuracy: 74.11764705882354\n",
      "Loss after a iteration 4900:0.7269311838936219 || Accuracy: 75.70588235294117\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmUElEQVR4nO3dd3xV9f3H8dc7IewNYS+ZIhuDUidqtSqt27pXtZZqW9vavWyrVm1tq611gKJ2qO2vonXUtrai4ECJigxBQfZQ9p5JPr8/7kUjJhDIDSe5eT8fj/vIved8z7mfb0LenHzvOeeriMDMzGq+nKQLMDOzzHCgm5llCQe6mVmWcKCbmWUJB7qZWZZwoJuZZQkHulWYpGckXZLptntZwwhJizO9330hqa2kCZI2SPp1BbeZL+nTVV1bZUl6XtIVFWwbknpWdU22Z3WSLsCqlqSNpV42BLYBxenXX4qIv1R0XxFxUlW0rcGuBFYCTaOMCzokPQAsjogf7e/CrHZyoGe5iGi887mk+cAVEfHfXdtJqhMRRfuztizQFXi7rDA3S4KHXGqpnUMXkr4r6X3gfkktJD0laYWkNennnUpt8+Gf4ZIulfSipFvTbedJOmkf2x5Qaujiv5L+IOnPFexH3/R7rZU0Q9IppdadLOnt9H6XSPpWennrdN/WSlotaaKkMn8XJB0mabKkdemvh6WXPwBcAnxH0sZdh1EkXQlcUGr9k6VWD5Y0Nb3Pv0qqX2q7z0qakq7tZUkDd9P3kHSVpNnpPl4vqYekVyStl/Q3SXVLtf+ipDnpPj8hqUOpdcdLmpWu6Q5Au7zXFyTNTP/8/i2p625+LJaUiPCjljyA+cCn089HAEXALUA9oAHQCjiT1NBME+D/gMdLbf88qSN8gEuBHcAXgVzgy8BSQPvQ9hXgVqAucASwHvhzOX0YQWoYAyAPmAP8IL3tscAGoE96/TLgyPTzFsDQ9PObgLvT2+cBR+6sZZf3agmsAS4i9dfseenXrdLrHwBu2M33+xPr0z+D14AO6f3PBEal1w0FlgOHpr9Pl6Tb1ytn/wE8ATQF+pEaTvsf0B1oBrwNXJJueyyp4aGh6Z/374EJ6XWt09/zs9Lfj2+k/23s/Pmdlv4+901/H34EvLxLHT2T/vftR/gIvZYrAa6LiG0RsSUiVkXEoxGxOSI2ADcCR+9m+wURMSYiioEHgfZA271pK6kLMAz4SURsj4gXSYVURQwHGgM3p7d9DniKVPBC6j+RgyQ1jYg1EfFGqeXtga4RsSMiJkY6mXYxEpgdEX+KiKKIeBiYBXyugvWV53cRsTQiVgNPAoPTy78I3BMRr0ZEcUQ8SCqkh+9mX7dExPqImAFMB/4TEXMjYh3wDDAk3e4CYGxEvBER24DvA5+S1A04mdTQ0d8jYgdwG/B+qff4EnBTRMyM1LDcL0j9leGj9GrGgV67rYiIrTtfSGoo6R5JCyStByYAzSXllrP9h7/0EbE5/bTxXrbtAKwutQxgUQXr7wAsioiSUssWAB3Tz88kFVYLJL0g6VPp5b8idcT5H0lzJX1vN/tfsMuy0vvfV6XDcjMffc+6Atemh1vWSloLdE7XUZ4PSj3fUsbrnfv+WF8iYiOwilRfOlDqe57+z630z6ArcHupmlaTGpKp7PfBMsyBXrvtelR6LdAHODQimgJHpZeLqrMMaCmpYallnSu47VKg8y7j312AJQARMTkiTgXaAI8Df0sv3xAR10ZEd1JH29+UdFw5+9/1KPTD/VfA3n5Yugi4MSKal3o0TP9lUFkf64ukRqSG2JaQ+hl0LrVOfPxnsIjUGVGl62oQES9noC7LIAe6ldaE1FHdWkktgeuq+g0jYgFQCPxUUt30UXRFhzReBTaR+uAxT9KI9LaPpPd1gaRm6WGE9aRP10x/8NgzHVw7lxeXsf9/Ar0lnS+pjqRzgINIDetUxAekxrMragwwStKhSmkkaaSkJnuxj/I8BFwmabCkeqSGTV6NiPnA00A/SWdIqgN8DWhXatu7ge9L6gcgqZmkszNQk2WYA91Ku43Uh6MrgUnAv/bT+14AfIrUEMANwF9JjR3vVkRsB04BTiJV853AxRExK93kImB+evhoFHBhenkv4L/ARlIfyN4ZEc+Xsf9VwGdJ/eWyCvgO8NmIWFnBft1Hagx/raTHK9CfQlLj6HeQ+vB1DqkPlCstIv4H/Bh4lNQReQ/g3PS6lcDZwM2k+tkLeKnUto+R+vD8kfT3cjqp77lVMzvPMjCrNiT9FZgVEVX+F4JZNvERuiVO0rD0+dM5kk4ETiU15m1me8FXilp10A4YR+pDusXAlyPizWRLMqt5PORiZpYlPORiZpYlEhtyad26dXTr1i2ptzczq5Fef/31lRGRX9a6xAK9W7duFBYWJvX2ZmY1kqRdr17+kIdczMyyhAPdzCxLONDNzLKEA93MLEs40M3MsoQD3cwsSzjQzcyyRI27l8s772/g6alLP75QH82/oLIXo1JrtMt0DeXN3vCx7XfdaC/eQ7tp+4la0gt23Ua7rlepupXa20dt9eH61NfUC6W3F5CT81E7gBylnud8uC+Ro48vz8lJLcuVkETuztc5ok5OTuprbmp5rlLP6+bmkJebQ16dHPJyRV5ODjk5VTlfhlntVeMCfc7yjfx+/JwPX/tWNDVPXq6on5dLg7xcGtRNfa2fl0vDurk0a5BH84Z1adEwj+YNU89bNqxLl1YN6dqqIfXqlDcbnpnVuEAfObA9IweO3GO70jcdKx36u+Z/eTcni4+1Kb287P1+fJ+fbF9WDTvfO3bdLsretvR2pbcJotQ2Hy2L2Pk6PtpHel1JfLSfnRO3lwSUpNtGqeclEelH+nlJUJxeV5x+XlwcFJUExSVBUUlJ6mtxsKOkhB1FJewoDrYXl7CjuIRtRSVs3VHM1h3FbNlezJYdxWzZUcLmbUXMWb6RNZt3sHbzdopKPv4NzhF0btmQHvmN6ZHfiO75jTmsRyu6tmpU9g/CrJapcYFeUaWHSMoZLdm5tsprsb0XEWzaXsyaTdtZvWk781dt4r0Vm3hvxUbmrtjES3NWsq0oNTf0p7q34txDOvOZfu2on+cjeKu9sjbQrWaTRON6dWhcrw6dWzZkUOfmH1tfUhIsXL2Zp6ct45HJC7nmkSk0a5DH6UM6cs6wzvRt3zSZws0SlNj90AsKCsI357JMKCkJJs1dxSOTF/Gv6e+zvbiEY/rk84cLhtKwro9ZLLtIej0iCspa53/tVuPl5IjDerbmsJ6tWbNpOw9PXsit/36HS8dOZuxlw2hcz//MrXbweeiWVVo0qstVI3py+7lDeH3hGi4Z+xobtu5Iuiyz/cKBblnpc4M6cMd5Q3hr0Vouuu811jvUrRZwoFvWOmlAe+68YCgzlq7jwntfZd1mh7plNwe6ZbUT+rXj7gsPZtayDZx/7yTWbNqedElmVWaPgS6ps6TxkmZKmiHpmjLaXCBpavrxsqRBVVOu2d47rm9b7rn4YGYv38j5977qMXXLWhU5Qi8Cro2IvsBw4GpJB+3SZh5wdEQMBK4HRme2TLPKOaZPG8ZcXMDsDzbwtYffpLgkmdN1zarSHgM9IpZFxBvp5xuAmUDHXdq8HBFr0i8nAZ0yXahZZR3dO5+fntKP8e+s4KZ/zky6HLOM26sTdCV1A4YAr+6m2eXAM+VsfyVwJUCXLl325q3NMuLC4V2Zs3wj9744j55tGnPuIf53aNmjwh+KSmoMPAp8PSLWl9PmGFKB/t2y1kfE6IgoiIiC/Pz8fanXrNJ+NLIvR/ZqzY8en86kuauSLscsYyoU6JLySIX5XyJiXDltBgL3AqdGhH9LrNqqk5vDHecPpWurhnz5z6+zYNWmpEsyy4iKnOUi4D5gZkT8ppw2XYBxwEUR8W5mSzTLvGYN8rjvkmEEcPmDhb7wyLJCRY7QDwcuAo6VNCX9OFnSKEmj0m1+ArQC7kyv9123rNrr1roRd11wMPNXbuIrD71JUXFJ0iWZVYrvtmi13sOvLeT746Zx6uAO/Obzg8n1FHlWjflui2a7cd4hXVizeTu//Nc75Er86uxBDnWrkRzoZsBVI3pSXBz8+tl3yckRvzxzoCezthrHgW6W9tXjelEcwW3/nU2dHPGL0wc41K1GcaCblXLNcb0oLgl+/9wccnLEjaf1/9j8tGbVmQPdrBRJfPP43hSVBHc9/x51csTPTunnULcawYFutgtJfOczfSguCUZPmEuDvFy+f3LfpMsy2yMHulkZJPH9kw5ky/Zi7pkwl/wm9bjiyO5Jl2W2Ww50s3JI4qen9GPlxm3c8PRM2jStzymDOiRdllm5PGOR2W7k5ojfnjOYQw5oybV/m8KLs1cmXZJZuRzoZntQPy+XMRcX0CO/MV/6UyHTl6xLuiSzMjnQzSqgWYM8HrjsEJo3rMul909m4arNSZdk9gkOdLMKatesPg9+4RCKSkq4eOyrrNy4LemSzD7GgW62F3q2acx9lwzj/fVbuerPb3huUqtWHOhme+ngri34xekDeG3+au4cPyfpcsw+5EA32wenD+nIKYM6cNv/ZvPGwjV73sBsP3Cgm+0DSdxwen/aNa3P1x+ZwgbPeGTVQEWmoOssabykmZJmSLqmjDaS9DtJcyRNlTS0aso1qz6a1s/j9nMHs3jNZq57YkbS5ZhV6Ai9CLg2IvoCw4GrJR20S5uTgF7px5XAXRmt0qyaKujWkq8c24txbyzhibeWJl2O1XJ7DPSIWBYRb6SfbwBmAh13aXYq8MdImQQ0l9Q+49WaVUNfO7YnQ7s054ePTWPxGp+fbsnZqzF0Sd2AIcCru6zqCCwq9Xoxnwx9JF0pqVBS4YoVK/ayVLPqqU5uDrefO4QI+MZfp3iyaUtMhQNdUmPgUeDrEbF+19VlbPKJE3QjYnREFEREQX5+/t5ValaNdW7ZkOtP68fk+Wu48/n3ki7HaqkKBbqkPFJh/peIGFdGk8VA51KvOwEeULRa5fQhnRg5sD1/GD+HVb6K1BJQkbNcBNwHzIyI35TT7Ang4vTZLsOBdRGxLIN1mtUI3/h0b7YVlfCnSQuSLsVqoYocoR8OXAQcK2lK+nGypFGSRqXb/BOYC8wBxgBXVU25ZtVbzzaNOe7ANvzxlQVs3VGcdDlWy+xxgouIeJGyx8hLtwng6kwVZVaTXXFkd84bM4lxbyzh/EO7JF2O1SK+UtQsw4Z3b8mAjs2498W5lPjmXbYfOdDNMkwSVxx5AHNXbOK5WcuTLsdqEQe6WRU4eUB7OjSrz5iJc5MuxWoRB7pZFcjLzeELRxzAq/NWM3Xx2qTLsVrCgW5WRc4Z1pkm9eowZuK8pEuxWsKBblZFmtTP47xDu/DPact8jxfbLxzoZlXo0sO6IeD+l+YnXYrVAg50syrUoXkDRg5szyOvLWTdFk+CYVXLgW5Wxb54ZHc2bS/mkdcWJl2KZTkHulkV69+xGZ/q3or7X5rPDt9a16qQA91sP7js8G68v34rE971PABWdRzoZvvBiD5taNmoLuPeWJJ0KZbFHOhm+0HdOjmcMqgDz878wB+OWpVxoJvtJ2cM7cj2ohL+Oc1TBVjVcKCb7ScDOjajZ5vGjHtjcdKlWJZyoJvtJ5I4Y2hHJs9fw4JVm5Iux7JQRaagGytpuaTp5axvJulJSW9JmiHpssyXaZYdThvcEQkee9MfjlrmVeQI/QHgxN2svxp4OyIGASOAX0uqW/nSzLJPh+YNOKxHK8a9sYTURF9mmbPHQI+ICcDq3TUBmqQnk26cbluUmfLMss8ZQzqxcPVmXl+wJulSLMtkYgz9DqAvsBSYBlwTEWVeDifpSkmFkgpXrPAFFlY7ndi/HQ3ycnnU56RbhmUi0D8DTAE6AIOBOyQ1LathRIyOiIKIKMjPz8/AW5vVPI3q1eGk/u14eupStu4oTrocyyKZCPTLgHGRMgeYBxyYgf2aZa0zhnZi/dYizzlqGZWJQF8IHAcgqS3QB/BEima78akerWjXtL7PSbeMqrOnBpIeJnX2SmtJi4HrgDyAiLgbuB54QNI0QMB3I2JllVVslgVyc8SpQzpw38R5rNy4jdaN6yVdkmWBPQZ6RJy3h/VLgRMyVpFZLXHGkE7c88JcnnxrKZcdfkDS5VgW8JWiZgnp064J/Ts29R0YLWMc6GYJOmNIJ6YtWcc7729IuhTLAg50swSdNqQj9fNyuHeizyOwynOgmyWoZaO6nDusC4+9uYQla7ckXY7VcA50s4R98ajuAIyZ4KN0qxwHulnCOjZvwGlDOvLI5IWs2rgt6XKsBnOgm1UDo47uwbaiEu5/aX7SpVgN5kA3qwZ6tmnMSf3b8eAr89mw1XOO2r5xoJtVE1eN6MmGrUX8edLCpEuxGsqBblZN9O/YjKN653Pfi3N9F0bbJw50s2rkqhE9WLlxO/9XuCjpUqwGcqCbVSOHHtCSg7u24O4X5rKjuMx5YszK5UA3q0YkcdWIHixZu4Un31qadDlWwzjQzaqZYw9sw4HtmnDn8+9RUuKJpK3iHOhm1YwkrjqmJ3OWb+TfM95PuhyrQRzoZtXQyAHt6dmmMb94ZiZbtvuMF6uYPQa6pLGSlkuavps2IyRNkTRD0guZLdGs9snNETec1p9Fq7fw++dmJ12O1RAVOUJ/ADixvJWSmgN3AqdERD/g7IxUZlbLDe/eijOHdmL0hLm8+4Hvl257tsdAj4gJwOrdNDkfGBcRC9PtPY25WYb8cGRfGtevww8fm+YPSG2PMjGG3htoIel5Sa9Luri8hpKulFQoqXDFihUZeGuz7NayUV1+cFJfJs9fw99fX5x0OVbNZSLQ6wAHAyOBzwA/ltS7rIYRMToiCiKiID8/PwNvbZb9zjq4E8O6teAXz8z07XVttzIR6IuBf0XEpohYCUwABmVgv2YG5OSIG08fwMatRdz0zKyky7FqLBOB/g/gSEl1JDUEDgVmZmC/ZpbWu20TrjyqO39/fTGT5q5Kuhyrpipy2uLDwCtAH0mLJV0uaZSkUQARMRP4FzAVeA24NyLKPcXRzPbNV4/tReeWDfjhY9PYVuRz0+2TFJHMJ+cFBQVRWFiYyHub1VTj31nOZfdP5trje/PV43olXY4lQNLrEVFQ1jpfKWpWgxzTpw0jB7Tn9+Pn8N6KjUmXY9WMA92shrnulINokJfL9x6d6nPT7WMc6GY1TJsm9fnhyNS56X95zdPV2Ucc6GY10NkHd+KInq255ZlZLFu3JelyrJpwoJvVQJL4xekDKC4JfvTYdJI6ucGqFwe6WQ3VpVVDrj2hN/+btZynpi5LuhyrBhzoZjXYZYcfwKBOzfjpEzNYs2l70uVYwhzoZjVYbo64+cyBrNuyg+uffjvpcixhDnSzGq5v+6Z8eUQPxr2xhBfe9V1MazMHulkWuPqYnnTPb8QPxk1j07aipMuxhDjQzbJA/bxcbjlzIEvWbuE3z76bdDmWEAe6WZYY1q0lFw7vwv0vzeOtRWuTLscS4EA3yyLfOfFA8pvU47uPTmVHcUnS5dh+5kA3yyJN6+dx/an9mfX+BsZMnJt0ObafOdDNsswJ/dpxUv923Pbf2cxbuSnpcmw/cqCbZaGfndKPenVy+P64qb4tQC1SkRmLxkpaLmm3sxBJGiapWNJZmSvPzPZFm6b1+cHJfZk0dzV/K1yUdDm2n1TkCP0B4MTdNZCUC9wC/DsDNZlZBpxT0JlDDmjJjU/PZPmGrUmXY/vBHgM9IiYAq/fQ7KvAo8DyTBRlZpWXkyNuOmMAW4tK+NkTvi1AbVDpMXRJHYHTgbsr0PZKSYWSCles8CXKZlWtR35jrjmuF09PW8Yz03xHxmyXiQ9FbwO+GxF7nIY8IkZHREFEFOTn52fgrc1sT648qjsDOjbjh49PZ+XGbUmXY1UoE4FeADwiaT5wFnCnpNMysF8zy4C83Bx+/flBbNxWxA/GTfNZL1ms0oEeEQdERLeI6Ab8HbgqIh6v7H7NLHN6t23Ct07ozX/e/oDH3lySdDlWRSpy2uLDwCtAH0mLJV0uaZSkUVVfnpllyuVHdGdYtxZc98QMz0OapZTUn18FBQVRWFiYyHub1VYLVm3ixNsmUtCtBX/8wiFISrok20uSXo+IgrLW+UpRs1qka6tG/GBkXybOXslDry1MuhzLMAe6WS1z4aFdOLJXa258eiYLVvleL9nEgW5Wy0jiljMHkivx7f+bSnGJz3rJFg50s1qoQ/MGXHdKP16bv5p7fZvdrOFAN6ulzhzakRP7tePW/7zDjKXrki7HMsCBblZLSal7vbRoWJevPzKFrTv2eLG3VXMOdLNarEWjutx69iBmL9/Izc/MSrocqyQHulktd1TvfC47vBsPvDyf59/xDVNrMge6mfHdEw+kd9vGfPvvU1nlG3jVWA50M6N+Xi63nzuEdZt38D3fwKvGcqCbGQB92zflOyf24dm3P+Cvkz1tXU3kQDezD33h8AM4vGcrfvbk28xb6atIaxoHupl9KCdH3Hr2IOrWyeHrj7zJjuKSpEuyveBAN7OPad+sATedMYC3Fq/jd/+bnXQ5thcc6Gb2CScPaM/ZB3fiD+PnMHn+nuaIt+rCgW5mZbrulH50btmQrz8yhfVbdyRdjlVARWYsGitpuaTp5ay/QNLU9ONlSYMyX6aZ7W+N69Xht+cM5v31W/nJ42X++ls1U5Ej9AeAE3ezfh5wdEQMBK4HRmegLjOrBoZ2acHXju3F41OW8o8pnou0uttjoEfEBKDcQbSIeDki1qRfTgI6Zag2M6sGrj6mBwd3bcGPHpvO4jWbky7HdiPTY+iXA89keJ9mlqA6uTncds5gAvjmX9/yhBjVWMYCXdIxpAL9u7tpc6WkQkmFK1asyNRbm1kV69yyIT8/NTUhxl3Pz0m6HCtHRgJd0kDgXuDUiFhVXruIGB0RBRFRkJ+fn4m3NrP95PQhHfncoA789r+zfSpjNVXpQJfUBRgHXBQR71a+JDOrjiTxi9P706lFA7760Jus3rQ96ZJsFxU5bfFh4BWgj6TFki6XNErSqHSTnwCtgDslTZFUWIX1mlmCmtTP4w/nD2X1pu18829TKPF4erVSZ08NIuK8Pay/ArgiYxWZWbXWv2Mzfvy5g/jx49O5Z8JcvjyiR9IlWZqvFDWzvXbhoV0YObA9t/7nHQo9nl5tONDNbK9J4uYzBqTG0x/2eHp14UA3s32yczx91cbtXOvx9GrBgW5m+6x/x2b8+LN9Gf/OCu6ZMDfpcmo9B7qZVcqFw7syckB7fvXvWYyftTzpcmo1B7qZVYokfnnWQPq2b8pXHnqDGUvXJV1SreVAN7NKa1SvDmMvHUbTBnl84YHJLFu3JemSaiUHupllRNum9bn/smFs2lbMZfdPZoMnxdjvHOhmljEHtmvKnRcMZfbyjXzloTcp8iTT+5UD3cwy6qje+dxwWn9eeHcFP/7HDCJ8OuP+ssdL/83M9tZ5h3Rh4erN3PX8e3Rt1ZBRR/v2APuDA93MqsS3T+jDotWbufmZWTRvkMe5h3RJuqSs50A3syqRkyNuPXsQG7YW8b1x0ygqCS4c3jXpsrKax9DNrMrUz8tl9MUHc9yBbfjR49N58OX5SZeU1RzoZlal6tXJ5a4LD+b4g9py3RMzuHeibxFQVRzoZlbl6tbJ4c4LhnJS/3bc8PRM7n7hvaRLykoVmbForKTlkqaXs16SfidpjqSpkoZmvkwzq+nycnP43XlD+OzA9tz8zCzueG520iVlnYocoT8AnLib9ScBvdKPK4G7Kl+WmWWjvNwcbjtnMKcN7sCt/3mXG59+m2LfdjdjKjIF3QRJ3XbT5FTgj5G6emCSpOaS2kfEskwVaWbZo05uDr/+/GCa1M9jzMR5zFu5mdvPHUyjej7prrIyMYbeEVhU6vXi9DIzszLl5ojrT+vPz07px3OzPuCsu19h6Vrf0KuyMhHoKmNZmX9DSbpSUqGkwhUrVmTgrc2sJrvksG6MvXQYi1dv5tQ/vMSURWuTLqlGy0SgLwY6l3rdCVhaVsOIGB0RBRFRkJ+fn4G3NrOabkSfNoy76jDq5+Vwzj2v8NTUMuPDKiATgf4EcHH6bJfhwDqPn5vZ3ujVtgmPX3U4Azo24ysPvcmt/37Hd2rcBxU5bfFh4BWgj6TFki6XNErSqHSTfwJzgTnAGOCqKqvWzLJWq8b1+MsXD+XzBZ24Y/wczh/zqsfV95KSurVlQUFBFBYWJvLeZla9PfbmYn742HTq1snhV2cN4viD2iZdUrUh6fWIKChrna8UNbNq5/QhnXjqq0fQsXkDvvjHQn76xAy2FRUnXVa150A3s2qpe35jxl11GJce1o0HXp7PGXe+zNwVG5Muq1pzoJtZtVWvTi4/PaUfYy4uYMnaLYz83YuMfXGery4thwPdzKq94w9qyzPXHMnw7i35+VNv8/l7XuE9H61/ggPdzGqE9s0aMPbSYfzm84OYs3wjJ98+kXteeM+nN5biQDezGkMSZwztxLPfOIqje+dz0zOzOPOul3n3gw1Jl1YtONDNrMZp07Q+91x0ML8/bwiL1mxh5O8mcvMzs9i0rSjp0hLlQDezGkkSnxvUgWe/cRSnDe7I3S+8x3G/foEn31pKUtfXJM2BbmY1WqvG9fjV2YN49MuH0bpJXb768JucP+bVWjkM40A3s6xwcNcW/OPqI7jhtP68vWw9J90+keufept1W3YkXdp+40A3s6yRmyMuHN6V8d8awecLOjP2pXmM+NV4xr44j+1F2X82jAPdzLJOy0Z1uemMATz11SPo16EZP3/qbY7/7Qs8PXVZVo+vO9DNLGv169CMP11+CA9cNowGeblc/dAbnHHXyxTOX510aVXCgW5mWU0SI/q04emvHckvzxrI0rVbOOvuV7jiwUJmLlufdHkZ5dvnmlmtsmV7MWNfmsfdL7zHxm1FfHZgB77x6V50z2+cdGkVsrvb5zrQzaxWWrd5B6MnvsfYF+ezvbiEs4Z24muf7kXH5g2SLm23HOhmZuVYsWEbdz4/h79MWgjA+Yd24csjetC2af2EKytbpSe4kHSipHckzZH0vTLWN5P0pKS3JM2QdFllizYz2x/ym9Tjus/1Y/y3R3DG0I78adICjvrleH7+5Nss37A16fL2yh6P0CXlAu8CxwOLgcnAeRHxdqk2PwCaRcR3JeUD7wDtImJ7efv1EbqZVUcLVm3i98/N4bE3l5CXKy4a3pUvHd2D1o3rJV0aUPkj9EOAORExNx3QjwCn7tImgCaSBDQGVgO1+y45ZlYjdW3ViFvPHsR/v3k0J/dvz30vzuPIW8Zz0z9nsnLjtqTL262KBHpHYFGp14vTy0q7A+gLLAWmAddExCcuy5J0paRCSYUrVqzYx5LNzKreAa0b8ZtzBvPsN4/mhH5tGTNxLkfc8hw/f/JtPlhfPYdiKhLoKmPZruM0nwGmAB2AwcAdkpp+YqOI0RFREBEF+fn5e1mqmdn+1yO/MbefO4Rnv3k0Jw9oz4OvzOfIX47nJ/+YztK1W5Iu72MqEuiLgc6lXncidSRe2mXAuEiZA8wDDsxMiWZmyeuR35jffH4wz117NKcP7shDry7k6F+N5/vjpjJ/5aakywMqFuiTgV6SDpBUFzgXeGKXNguB4wAktQX6AHMzWaiZWXXQtVUjbjlrIM9/ewTnDOvMo68v4dhfP89XHnqDGUvXJVpbhc5Dl3QycBuQC4yNiBsljQKIiLsldQAeANqTGqK5OSL+vLt9+iwXM8sGy9dv5b6X5vGXSQvZuK2Io3vnc9WIHhxyQEtS54lkli8sMjOrYuu27ODPkxYw9sV5rNq0naFdmvOlo3twfN+25ORkLtgd6GZm+8nWHcX8X+Ei7pkwl8VrtnBA60ZcceQBnDm0E/Xzciu9fwe6mdl+VlRcwr9mvM/oCXOZungdrRrV5eJPdeOiT3WlZaO6+7xfB7qZWUIiglfnrWb0hLk8N2s59fNy+NYJfbjiyO77tL/dBXqdSlVqZma7JYnh3VsxvHsrZn+wgTET59KpRdXc0dGBbma2n/Rq24RfnjWoyvbvGYvMzLKEA93MLEs40M3MsoQD3cwsSzjQzcyyhAPdzCxLONDNzLKEA93MLEskdum/pBXAgn3cvDWwMoPl1CS1te/ud+3ifpeva0SUOeVbYoFeGZIKy7uXQbarrX13v2sX93vfeMjFzCxLONDNzLJETQ300UkXkKDa2nf3u3Zxv/dBjRxDNzOzT6qpR+hmZrYLB7qZWZaocYEu6URJ70iaI+l7SddTVSSNlbRc0vRSy1pKelbS7PTXFknWWBUkdZY0XtJMSTMkXZNentV9l1Rf0muS3kr3+2fp5Vnd750k5Up6U9JT6ddZ329J8yVNkzRFUmF6WaX6XaMCXVIu8AfgJOAg4DxJByVbVZV5ADhxl2XfA/4XEb2A/6VfZ5si4NqI6AsMB65O/4yzve/bgGMjYhAwGDhR0nCyv987XQPMLPW6tvT7mIgYXOrc80r1u0YFOnAIMCci5kbEduAR4NSEa6oSETEBWL3L4lOBB9PPHwRO25817Q8RsSwi3kg/30Dql7wjWd73SNmYfpmXfgRZ3m8ASZ2AkcC9pRZnfb/LUal+17RA7wgsKvV6cXpZbdE2IpZBKviANgnXU6UkdQOGAK9SC/qeHnaYAiwHno2IWtFv4DbgO0BJqWW1od8B/EfS65KuTC+rVL9r2iTRKmOZz7vMQpIaA48CX4+I9VJZP/rsEhHFwGBJzYHHJPVPuKQqJ+mzwPKIeF3SiITL2d8Oj4ilktoAz0qaVdkd1rQj9MVA51KvOwFLE6olCR9Iag+Q/ro84XqqhKQ8UmH+l4gYl15cK/oOEBFrgedJfYaS7f0+HDhF0nxSQ6jHSvoz2d9vImJp+uty4DFSQ8qV6ndNC/TJQC9JB0iqC5wLPJFwTfvTE8Al6eeXAP9IsJYqodSh+H3AzIj4TalVWd13SfnpI3MkNQA+Dcwiy/sdEd+PiE4R0Y3U7/NzEXEhWd5vSY0kNdn5HDgBmE4l+13jrhSVdDKpMbdcYGxE3JhsRVVD0sPACFK30/wAuA54HPgb0AVYCJwdEbt+cFqjSToCmAhM46Mx1R+QGkfP2r5LGkjqQ7BcUgdaf4uIn0tqRRb3u7T0kMu3IuKz2d5vSd1JHZVDauj7oYi4sbL9rnGBbmZmZatpQy5mZlYOB7qZWZZwoJuZZQkHuplZlnCgm5llCQe6mVmWcKCbmWWJ/wesxRXXqRk5bwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model  = Classifier(1024, [32,32, 10])\n",
    "model.forward_pass(X_test)\n",
    "loss = model.compute_loss_with_l2(model.output3_act, y_test)\n",
    "model.backward_pass_with_l2(y_test, iteration = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45ebb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c876e7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_3_act' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pr \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mClassifier.predict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m    270\u001b[0m output3     \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(output2_act, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights3, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases3)\n\u001b[1;32m    271\u001b[0m output3_act \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSoftmax(output3)\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43moutput_3_act\u001b[49m)\n\u001b[1;32m    273\u001b[0m prediction, prediction_prob \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output3_act, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39mmax(output3_act, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction, output3_act\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_3_act' is not defined"
     ]
    }
   ],
   "source": [
    "pr = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63beb148",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpr_1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1023aade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10941    6\n",
       "5250     3\n",
       "10292    6\n",
       "2266     1\n",
       "6398     3\n",
       "        ..\n",
       "4706     2\n",
       "8404     4\n",
       "11114    6\n",
       "7877     4\n",
       "6188     3\n",
       "Name: character, Length: 3400, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0cfc35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexs = np.arange(0, 100) * 100\n",
    "value = [x * 100 for x in model.loss_list]\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.title(\"Training Loss of the Model\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(indexs,value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d462ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model  = Classifier(1024, [32,16, 10])\n",
    "# model.forward_pass(X_train)\n",
    "# loss = model.compute_loss_with_l2(model.output3_act, y_train)\n",
    "# model.backward_pass(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "759f6c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after a iteration 0:2.302677164824908 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 100:2.3025389759383508 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 200:2.302351830029192 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 300:2.3017235407476075 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 400:2.2929413144350352 || Accuracy: 21.404411764705884\n",
      "Loss after a iteration 500:1.6143845966005945 || Accuracy: 29.772058823529413\n",
      "Loss after a iteration 600:1.423897904104247 || Accuracy: 41.61764705882353\n",
      "Loss after a iteration 700:0.8854916359191214 || Accuracy: 66.31617647058825\n",
      "Loss after a iteration 800:0.6372958570952105 || Accuracy: 76.52941176470588\n",
      "Loss after a iteration 900:0.5454960065193428 || Accuracy: 79.02941176470588\n",
      "Loss after a iteration 1000:0.5032702979940298 || Accuracy: 80.83088235294117\n",
      "Loss after a iteration 1100:0.47472469876328915 || Accuracy: 83.41911764705883\n",
      "Loss after a iteration 1200:0.43057262951013375 || Accuracy: 86.66176470588235\n",
      "Loss after a iteration 1300:0.3828469975821947 || Accuracy: 88.78676470588235\n",
      "Loss after a iteration 1400:0.35975827185091636 || Accuracy: 89.40441176470588\n",
      "Loss after a iteration 1500:0.3470982703674689 || Accuracy: 89.79411764705883\n",
      "Loss after a iteration 1600:0.33681875953964996 || Accuracy: 90.13970588235294\n",
      "Loss after a iteration 1700:0.3279748757707646 || Accuracy: 90.4264705882353\n",
      "Loss after a iteration 1800:0.31908318847981276 || Accuracy: 90.81617647058823\n",
      "Loss after a iteration 1900:0.30989515146194346 || Accuracy: 91.05882352941177\n",
      "Loss after a iteration 2000:0.29929196663209734 || Accuracy: 91.54411764705883\n",
      "Loss after a iteration 2100:0.2874617624111387 || Accuracy: 92.07352941176471\n",
      "Loss after a iteration 2200:0.2763098060414592 || Accuracy: 92.36764705882354\n",
      "Loss after a iteration 2300:0.26694142469572546 || Accuracy: 92.63970588235294\n",
      "Loss after a iteration 2400:0.2587586295641177 || Accuracy: 92.84558823529412\n",
      "Loss after a iteration 2500:0.2517297910854554 || Accuracy: 93.125\n",
      "Loss after a iteration 2600:0.244999777925549 || Accuracy: 93.32352941176471\n",
      "Loss after a iteration 2700:0.23850967340352935 || Accuracy: 93.5514705882353\n",
      "Loss after a iteration 2800:0.23275451897443966 || Accuracy: 93.79411764705883\n",
      "Loss after a iteration 2900:0.22869561034384447 || Accuracy: 93.86764705882354\n",
      "Loss after a iteration 3000:0.22802265796044383 || Accuracy: 93.90441176470588\n",
      "Loss after a iteration 3100:0.2405705075244186 || Accuracy: 93.15441176470588\n",
      "Loss after a iteration 3200:0.21092529334526344 || Accuracy: 94.38970588235294\n",
      "Loss after a iteration 3300:0.2079088401130079 || Accuracy: 94.4779411764706\n",
      "Loss after a iteration 3400:0.2053395217460258 || Accuracy: 94.5735294117647\n",
      "Loss after a iteration 3500:0.20301777959421863 || Accuracy: 94.61764705882352\n",
      "Loss after a iteration 3600:0.20143485759737093 || Accuracy: 94.63970588235294\n",
      "Loss after a iteration 3700:0.20091197534208002 || Accuracy: 94.69852941176471\n",
      "Loss after a iteration 3800:0.32679981255391527 || Accuracy: 88.41176470588236\n",
      "Loss after a iteration 3900:0.19435445212797603 || Accuracy: 94.91176470588235\n",
      "Loss after a iteration 4000:0.19266035080626032 || Accuracy: 95.0220588235294\n",
      "Loss after a iteration 4100:0.1913428537325238 || Accuracy: 95.05882352941177\n",
      "Loss after a iteration 4200:0.19036458884939508 || Accuracy: 95.0735294117647\n",
      "Loss after a iteration 4300:0.3695286788519291 || Accuracy: 87.58088235294117\n",
      "Loss after a iteration 4400:0.1862380149707637 || Accuracy: 95.23529411764706\n",
      "Loss after a iteration 4500:0.18453319062073648 || Accuracy: 95.27205882352942\n",
      "Loss after a iteration 4600:0.18334981885411586 || Accuracy: 95.32352941176471\n",
      "Loss after a iteration 4700:0.18390251001814817 || Accuracy: 95.31617647058823\n",
      "Loss after a iteration 4800:0.18008765864575782 || Accuracy: 95.36029411764706\n",
      "Loss after a iteration 4900:0.17852427084990227 || Accuracy: 95.44117647058825\n",
      "Loss after a iteration 5000:0.17736345961969846 || Accuracy: 95.4779411764706\n",
      "Loss after a iteration 5100:0.17716972691344401 || Accuracy: 95.5\n",
      "Loss after a iteration 5200:0.18398154016721738 || Accuracy: 94.79411764705883\n",
      "Loss after a iteration 5300:0.17301654951488807 || Accuracy: 95.6029411764706\n",
      "Loss after a iteration 5400:0.17201830811080654 || Accuracy: 95.63970588235294\n",
      "Loss after a iteration 5500:0.17138867683574902 || Accuracy: 95.67647058823529\n",
      "Loss after a iteration 5600:0.30184220202294443 || Accuracy: 89.01470588235294\n",
      "Loss after a iteration 5700:0.16848475554092388 || Accuracy: 95.69117647058823\n",
      "Loss after a iteration 5800:0.16774606960522756 || Accuracy: 95.75\n",
      "Loss after a iteration 5900:0.1673255313274211 || Accuracy: 95.78676470588235\n"
     ]
    }
   ],
   "source": [
    "model  = Classifier(1024, [32,32, 10])\n",
    "model.forward_pass(X_train)\n",
    "loss = model.compute_loss_with_l2(model.output3_act, y_train)\n",
    "model.backward_pass_with_l2(y_train, iteration = 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a80cde9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "model.save_model(f'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8268bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model: 88.17647058823529\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "y_acc = np.mean((y_test == y_test_pred))\n",
    "print(f'Test Accuracy of the model: {y_acc * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ffe91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 6, ..., 6, 4, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7892a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'1': model.weights1, '2': model.weights2, '3': model.weights3, \n",
    "           'b1':model.biases1,'b2':model.biases1,'b3':model.biases1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cbcf294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'base_model_weights_88.pkl'\n",
    "pickle.dump(weights, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c00ff0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'base_model_100.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daecd9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 2 6 ... 6 4 3]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(X_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1997142e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6402f6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afb27453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "# foo = Image.open('dataset/Test/digit_0/103277.png')  # My image is a 200x374 jpeg that is 102kb large\n",
    "foo = Image.open('number-5.png')\n",
    "foo= foo.convert('L')\n",
    "foo = foo.resize((32,32))\n",
    "# print(foo.size)  # (200, 374)\n",
    "image = np.array(foo)\n",
    "\n",
    "image = image.reshape(-1)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16ba2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Image.fromarray(image)\n",
    "      \n",
    "    # saving the final output \n",
    "    # as a PNG file\n",
    "data.save('gfg_dummy_pic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13f74b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastapi import FastAPI, File\n",
    "# from fastapi.middleware.cors import CORSMiddleware\n",
    "# from PIL import Image\n",
    "# import io\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import uvicorn\n",
    "# # import Classifier\n",
    "\n",
    "# app = FastAPI()\n",
    "# origins = [\n",
    "#     'http://localhost:8000',\n",
    "# ]\n",
    "# model = Classifier(1024, [32,32,10])\n",
    "# filename = 'base_model.pkl'\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# # print(loaded_model.weights1)\n",
    "# result = loaded_model.predict(X_test)\n",
    "\n",
    "# @app.get(\"/\")\n",
    "# async def root():\n",
    "#     return {\"message\": \"Wrong Method\"}\n",
    "\n",
    "# @app.post(\"/image\")\n",
    "# async def upload(file: bytes = File(...)):\n",
    "#     print(result)\n",
    "#     image = Image.open(io.BytesIO(file))\n",
    "# #     image.show()\n",
    "#     image = np.array(image)\n",
    "# #     image = image.resize((32, 32))\n",
    "# #     image = image.reshape(-1,)\n",
    "#     print(image.shape)\n",
    "#     # result = model.predict(image)\n",
    "#     print(\"The result is :\", result)\n",
    "#     return {\"Upload Status\": \"Complete\"}\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     config = uvicorn.Config(app)\n",
    "#     server = uvicorn.Server(config)\n",
    "#     await server.serve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc7772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
