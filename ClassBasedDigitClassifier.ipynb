{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d63ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd65f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = {\n",
    "                'digit_0' : 0,\n",
    "                'digit_1' : 1,\n",
    "                'digit_2' : 2,\n",
    "                'digit_3' : 3,\n",
    "                'digit_4' : 4,\n",
    "                'digit_5' : 5,\n",
    "                'digit_6' : 6,\n",
    "                'digit_7' : 7,\n",
    "                'digit_8' : 8,\n",
    "                'digit_9' : 9,\n",
    "}\n",
    "train_data = pd.read_csv('./dataset/train_digits_data.csv')\n",
    "test_data  = pd.read_csv('./dataset/test_digits_data.csv')\n",
    "X_train = train_data.iloc[:, :-1].values\n",
    "y_train = train_data.iloc[:, -1]\n",
    "y_train = y_train.replace(charset)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61885a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "X_train = mm.fit_transform(X_train)\n",
    "# X_dev   = mm.fit_transform(X_dev)\n",
    "X_test = mm.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5185ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f76d683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\t\t\t Before Processing\t After Processing\n",
      "=================================================================\n",
      "Training Set Images:\t(17000, 1025)\t\t(13600, 1024)\n",
      "Training Set Labels:\t(17000,)\t\t(13600,)\n",
      "Test Set Images:\t(3000, 1025)\t\t(3400, 1024)\n",
      "Test Set Labels:\t(3000,)\t\t\t(3000,)\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Data\\t\\t\\t\",\"Before Processing\\t\",\"After Processing\")\n",
    "print(\"=================================================================\")\n",
    "print(\"Training Set Images:\\t\" + str(train_data.shape)+\"\\t\\t\"+ str(X_train.shape))\n",
    "print(\"Training Set Labels:\\t\" + str(train_data.iloc[:, -1].shape)+\"\\t\\t\"+ str(y_train.shape))\n",
    "# print(\"Dev Set Images:\\t\\t\" + str(X_dev.shape)+\"\\t\\t\"+ str(X_dev.shape))\n",
    "# print(\"Dev Set Labels:\\t\\t\" + str(y_dev.shape)+\"\\t\\t\\t\"+ str(y_dev.shape))\n",
    "print(\"Test Set Images:\\t\" + str(test_data.shape)+\"\\t\\t\"+ str(X_test.shape))\n",
    "print(\"Test Set Labels:\\t\" + str(test_data.iloc[:, -1].shape)+\"\\t\\t\\t\"+ str(test_data.iloc[:, -1].shape))\n",
    "print(\"=================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a695ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier:\n",
    "    def __init__(self, n_inputs, n_neurons = [32,32,10]):\n",
    "        np.random.seed(42)\n",
    "    # We have done here n_inputs/n_neurons instead of n_neurons/n_inputs to prevent the Transpose everytime\n",
    "        self.weights1 = 0.01 * np.random.randn(n_inputs, n_neurons[0]) # The input shape and no of neurons you want to have in the layer\n",
    "        self.biases1 =  0.01 * np.random.randn(1, n_neurons[0])\n",
    "        self.weights2 = 0.01 *np.random.randn(n_neurons[0], n_neurons[1]) # The input shape and no of neurons you want to have in the layer\n",
    "        self.biases2 = 0.01 * np.random.randn(1, n_neurons[1])\n",
    "        self.weights3 = 0.01 * np.random.randn(n_neurons[1], n_neurons[2])\n",
    "        self.biases3 = 0.01 * np.random.randn(1, n_neurons[2])\n",
    "        self.output1 = None\n",
    "        self.output2 = None\n",
    "        self.output3 = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        # activatied outputs\n",
    "        self.output1_act = None\n",
    "        self.output2_act = None\n",
    "        self.output3_act = None\n",
    "    def forward(self, inputs, weights, biases):\n",
    "        \"\"\" The dot product of the input - weights - Biases (y = Wx + b) \"\"\"\n",
    "        output = np.dot(inputs, weights) + biases\n",
    "        if(np.isnan(np.sum(output))):\n",
    "            raise Exception(\"NaN values present in FW pass\")\n",
    "        elif(np.isinf(np.sum(output))):\n",
    "            raise Exception(\"INF values present in FW Pass\")\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def ReLU(self, inputs):\n",
    "        \"\"\" Rectified Linear Activation Function \"\"\"\n",
    "        output = np.maximum(0, inputs)\n",
    "        return output\n",
    "    \n",
    "    def Softmax(self, inputs):\n",
    "    # subtract largest value to prevent overflow\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                            keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        if(np.isnan(np.sum(probabilities))):\n",
    "            raise Exception(\"NaN values present in Softmax For\")\n",
    "        elif(np.isinf(np.sum(probabilities))):\n",
    "            raise Exception(\"INF values present in Softmax For\")\n",
    "        \n",
    "        return probabilities\n",
    "        \n",
    "    def categorical_cross_entropy(self,y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-6, 1-1e-6)\n",
    "        # Handling if labels are 1D \n",
    "        correct_confidences = None\n",
    "        if len(y_true.shape) == 1:\n",
    "#             print(y_pred_clipped[range(samples), :].shape)\n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "        elif len(y_true.shape) ==2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true, axis =1)\n",
    "        else:\n",
    "            raise Exception(\"Sorry, no numbers below zero\")\n",
    "        \n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "#         print(negative_log_likelihoods.shape)\n",
    "        return negative_log_likelihoods \n",
    "    \n",
    "    def linear_backward(self,inputs, weights, dvalues):\n",
    "        self.dweights_linear = np.dot(inputs.T, dvalues)\n",
    "        self.dbiases_linear = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dinput_linear = np.dot(dvalues, weights.T)\n",
    "        \n",
    "        if(np.isnan(np.sum(self.dweights_linear))):\n",
    "            raise Exception(\"NaN values present in Linear Back\")\n",
    "        elif(np.isinf(np.sum(self.dweights_linear))):\n",
    "            raise Exception(\"INF values present in Linear BAck\")\n",
    "        \n",
    "        \n",
    "        return self.dweights_linear, self.dinput_linear\n",
    "    \n",
    "    def linear_backward_with_l2(self,inputs, weights, dvalues, lambd = 0.5):\n",
    "        \"\"\"  \"\"\"\n",
    "        m = inputs.shape[1]\n",
    "        self.dweights_linear = np.dot(inputs.T, dvalues) + (lambd*weights)/m\n",
    "        self.dbiases_linear = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dinput_linear = np.dot(dvalues, weights.T) \n",
    "        \n",
    "        if(np.isnan(np.sum(self.dweights_linear))):\n",
    "            raise Exception(\"NaN values present in Linear Back\")\n",
    "        elif(np.isinf(np.sum(self.dweights_linear))):\n",
    "            raise Exception(\"INF values present in Linear BAck\")\n",
    "        \n",
    "        \n",
    "        return self.dweights_linear, self.dinput_linear\n",
    "    \n",
    "    def softmax_backward(self,dA, Z):\n",
    "        \"\"\"Compute backward pass for softmax activation\"\"\"\n",
    "        softmax_output = Softmax(Z) \n",
    "        return softmax_output * (1 - softmax_output) * dA\n",
    "\n",
    "    def ReLU_backward(self,dA, Z):\n",
    "        \n",
    "        dZ = np.array(dA, copy=True)\n",
    "        dZ[Z <= 0] = 0\n",
    "        if(np.isnan(np.sum(dZ))):\n",
    "            raise Exception(\"NaN values present in RELU Back\")\n",
    "        elif(np.isinf(np.sum(dZ))):\n",
    "            raise Exception(\"INF values present in RELU BAck\")\n",
    "        return dZ\n",
    "        \n",
    "    def categorical_cross_entropy_backward(self, dvalues, y_true):\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs_loss = self.dinputs / samples\n",
    "        if(np.isnan(np.sum(self.dinputs))):\n",
    "            raise Exception(\"NaN values present in Softmax Back\")\n",
    "        elif(np.isinf(np.sum(self.dinputs))):\n",
    "            raise Exception(\"INF values present in Softmax_back\")\n",
    "        return self.dinputs\n",
    "    \n",
    "    def softmax_categorical_cross_entropy_combined_backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        #handling Ohe values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs_combined = dvalues.copy()\n",
    "        # Calculate gradient\n",
    "        self.dinputs_combined[range(samples), y_true] -= 1\n",
    "        # Normalize gradient\n",
    "        self.dinputs_combined = self.dinputs_combined / samples\n",
    "        if(np.isnan(np.sum(self.dinputs_combined))):\n",
    "            raise Exception(\"NaN values present in Softmax Back\")\n",
    "        elif(np.isinf(np.sum(self.dinputs_combined))):\n",
    "            raise Exception(\"INF values present in Softmax_back\")\n",
    "       \n",
    "        return self.dinputs_combined\n",
    "        \n",
    "    \n",
    "    def compute_loss(self,y_pred, y_true):\n",
    "        sample_losses = self.categorical_cross_entropy(y_pred, y_true)\n",
    "        loss = np.mean(sample_losses)\n",
    "        return loss\n",
    "    \n",
    "    def compute_loss_with_l2(self,y_pred, y_true, lambd = 0.5):\n",
    "        m = 10\n",
    "        sample_losses = self.categorical_cross_entropy(y_pred, y_true)\n",
    "        L2_regularization_cost = (lambd/(2*m))*(np.sum(np.square(self.weights1) + np.sum(np.square(self.weights2) + np.sum(np.square(self.weights3)))))\n",
    "        loss = np.mean(sample_losses) \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "        self.X = X\n",
    "        self.output1     = self.forward(self.X, self.weights1, self.biases1)\n",
    "        self.output1_act = self.ReLU(self.output1)\n",
    "        self.output2     = self.forward(self.output1_act, self.weights2, self.biases2)\n",
    "        self.output2_act = self.ReLU(self.output2)\n",
    "        self.output3     = self.forward(self.output2_act, self.weights3, self.biases3)\n",
    "        self.output3_act = self.Softmax(self.output3)\n",
    "#         print(\"Softmax SUM\", np.sum(self.output3_act, axis = 1))\n",
    "        if(np.isnan(np.sum(self.output3_act))):\n",
    "            raise Exception(\"NaN values present in data\")\n",
    "        elif(np.isinf(np.sum(self.output3_act))):\n",
    "            raise Exception(\"INF values present in data\")\n",
    "        \n",
    "        \n",
    "    def check_inf(self):\n",
    "        check_weights = np.any(np.isinf(self.weights1)) or np.any(np.isinf(self.weights2)) or np.any(np.isinf(self.weights3))\n",
    "        check_bias    = np.any(np.isinf(self.biases1)) or np.any(np.isinf(self.biases2)) or np.any(np.isinf(self.biases3))\n",
    "        return (check_weights or check_bias)\n",
    "    \n",
    "    def backward_pass(self, y, learning_rate= 0.1, iteration = 10000):\n",
    "        self.y = y\n",
    "        for i in range(iteration):\n",
    "            self.forward_pass(self.X)\n",
    "            predictions = np.argmax(self.output3_act, axis=1)\n",
    "            \n",
    "            \n",
    "            gradient_output3_act                  = self.softmax_categorical_cross_entropy_combined_backward(self.output3_act, self.y)\n",
    "            gradient_output3, gradient_input3     = self.linear_backward(self.output2,self.weights3,gradient_output3_act)\n",
    "            gradient_output2_act                  = self.ReLU_backward(gradient_input3, self.output2)\n",
    "            gradient_output2, gradient_input2     = self.linear_backward(self.output1, self.weights2, gradient_output2_act)\n",
    "            gradient_output1_act                  = self.ReLU_backward(gradient_input2, self.output1)\n",
    "            gradient_output1, gradient_input1     = self.linear_backward(self.X, self.weights1, gradient_output1_act)\n",
    "            \n",
    "            self.weights3  = self.weights3 - learning_rate * gradient_output3\n",
    "            self.weights2  = self.weights2 - learning_rate * gradient_output2\n",
    "            self.weights1  = self.weights1 - learning_rate * gradient_output1\n",
    "            assert np.sum(gradient_output1) != np.nan, \"The gradient has nan\"\n",
    "            assert np.sum(gradient_output1) != np.inf, \"The gradient has inf\"\n",
    "            if i%100 == 0:\n",
    "\n",
    "                loss = self.compute_loss(self.output3_act, y)\n",
    "                self.accuracy = np.mean(predictions==self.y)\n",
    "                if(self.accuracy > 99.0):\n",
    "                    break\n",
    "                print(f'Loss after a iteration {i}:{loss} || Accuracy: {self.accuracy * 100}')\n",
    "                \n",
    "    def backward_pass_with_l2(self, y, learning_rate= 0.1, iteration = 10000):\n",
    "        self.y = y\n",
    "        self.loss_list = []\n",
    "        self.acc_list = []\n",
    "        for i in range(iteration):\n",
    "            self.forward_pass(self.X)\n",
    "            predictions = np.argmax(self.output3_act, axis=1)\n",
    "            \n",
    "            \n",
    "            gradient_output3_act                  = self.softmax_categorical_cross_entropy_combined_backward(self.output3_act, self.y)\n",
    "            gradient_output3, gradient_input3     = self.linear_backward_with_l2(self.output2,self.weights3,gradient_output3_act)\n",
    "            gradient_output2_act                  = self.ReLU_backward(gradient_input3, self.output2)\n",
    "            gradient_output2, gradient_input2     = self.linear_backward_with_l2(self.output1, self.weights2, gradient_output2_act)\n",
    "            gradient_output1_act                  = self.ReLU_backward(gradient_input2, self.output1)\n",
    "            gradient_output1, gradient_input1     = self.linear_backward_with_l2(self.X, self.weights1, gradient_output1_act)\n",
    "            \n",
    "            self.weights3  = self.weights3 - learning_rate * gradient_output3\n",
    "            self.weights2  = self.weights2 - learning_rate * gradient_output2\n",
    "            self.weights1  = self.weights1 - learning_rate * gradient_output1\n",
    "            assert np.sum(gradient_output1) != np.nan, \"The gradient has nan\"\n",
    "            assert np.sum(gradient_output1) != np.inf, \"The gradient has inf\"\n",
    "            loss = self.compute_loss_with_l2(self.output3_act, y)\n",
    "            self.accuracy = np.mean(predictions==self.y)\n",
    "            if i%100 == 0:\n",
    "                self.loss_list.append(loss)\n",
    "                self.acc_list.append(self.accuracy)\n",
    "                if(self.accuracy > .99):\n",
    "                    break\n",
    "                print(f'Loss after a iteration {i}:{loss} || Accuracy: {self.accuracy * 100}')\n",
    "        plt.plot(self.loss_list)\n",
    "        plt.title(\"Training loss of the model\")\n",
    "    def load_model(self, weights, biases):\n",
    "        self.weights1 = weights['1']\n",
    "        self.weights2 = weights['2']\n",
    "        self.weights3 = weights['3']\n",
    "        \n",
    "        self.biases1 = weights['b1']\n",
    "        self.biases2 = weights['b2']\n",
    "        self.biases3 = weights['b3']\n",
    "    \n",
    "    def save_model(self, filename = f'model.pkl'):\n",
    "        from datetime import date\n",
    "\n",
    "        today = date.today()\n",
    "\n",
    "        filename = f'model_{self.accuracy}-{today}.pkl'\n",
    "        weights = {\n",
    "                    '1': self.weights1, '2': self.weights2, '3': self.weights3, \n",
    "                    'b1':self.biases1,'b2':self.biases2,'b3':self.biases3\n",
    "        }\n",
    "        pickle.dump(weights, open(filename, 'wb'))\n",
    "        \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        output1     = self.forward(X_test, self.weights1, self.biases1)\n",
    "        output1_act = self.ReLU(output1)\n",
    "        output2     = self.forward(output1_act, self.weights2, self.biases2)\n",
    "        output2_act = self.ReLU(output2)\n",
    "        output3     = self.forward(output2_act, self.weights3, self.biases3)\n",
    "        output3_act = self.Softmax(output3)\n",
    "        prediction, prediction_prob = np.argmax(output3_act, axis=1), np.max(output3_act, axis=1)\n",
    "        return prediction, output3_act\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16fc187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after a iteration 0:2.302677164824908 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 100:2.302515542595861 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 200:2.3022127735814624 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 300:2.300683098220567 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 400:2.182657292285168 || Accuracy: 21.97794117647059\n",
      "Loss after a iteration 500:1.4683099749842623 || Accuracy: 39.38970588235294\n",
      "Loss after a iteration 600:0.8797050229800318 || Accuracy: 69.33088235294119\n",
      "Loss after a iteration 700:0.6028793855155222 || Accuracy: 78.03676470588236\n",
      "Loss after a iteration 800:0.5310540704291291 || Accuracy: 80.11029411764706\n",
      "Loss after a iteration 900:0.4879849582026894 || Accuracy: 82.27205882352942\n",
      "Loss after a iteration 1000:0.44330377050061814 || Accuracy: 84.18382352941177\n",
      "Loss after a iteration 1100:0.3811342484782405 || Accuracy: 87.55147058823529\n",
      "Loss after a iteration 1200:0.34351750182304064 || Accuracy: 89.61764705882352\n",
      "Loss after a iteration 1300:0.32504589252958355 || Accuracy: 90.2720588235294\n",
      "Loss after a iteration 1400:0.3116099262430049 || Accuracy: 90.8235294117647\n",
      "Loss after a iteration 1500:0.29914956911663243 || Accuracy: 91.32352941176471\n",
      "Loss after a iteration 1600:0.28724188557406055 || Accuracy: 91.71323529411765\n",
      "Loss after a iteration 1700:0.2740894134933013 || Accuracy: 92.15441176470588\n",
      "Loss after a iteration 1800:0.2609544508131522 || Accuracy: 92.625\n",
      "Loss after a iteration 1900:0.24868312799584147 || Accuracy: 92.98529411764706\n",
      "Loss after a iteration 2000:0.23891875633709403 || Accuracy: 93.30147058823529\n",
      "Loss after a iteration 2100:0.23073890540938669 || Accuracy: 93.42647058823529\n",
      "Loss after a iteration 2200:0.22372124714168914 || Accuracy: 93.58823529411765\n",
      "Loss after a iteration 2300:0.21791952352513533 || Accuracy: 93.75735294117648\n",
      "Loss after a iteration 2400:0.21323361547781702 || Accuracy: 93.86029411764706\n",
      "Loss after a iteration 2500:0.20387842581982452 || Accuracy: 94.34558823529412\n",
      "Loss after a iteration 2600:0.23079753712516818 || Accuracy: 92.5\n",
      "Loss after a iteration 2700:0.1937135737288496 || Accuracy: 94.80147058823529\n",
      "Loss after a iteration 2800:0.19252432408572343 || Accuracy: 94.81617647058823\n",
      "Loss after a iteration 2900:0.1861335756109253 || Accuracy: 95.06617647058823\n",
      "Loss after a iteration 3000:0.1837246600049155 || Accuracy: 95.08823529411765\n",
      "Loss after a iteration 3100:0.18235665979884821 || Accuracy: 95.13235294117646\n",
      "Loss after a iteration 3200:0.17830672547173002 || Accuracy: 95.26470588235294\n",
      "Loss after a iteration 3300:0.17634454758902202 || Accuracy: 95.34558823529412\n",
      "Loss after a iteration 3400:0.1750073038146807 || Accuracy: 95.41911764705883\n",
      "Loss after a iteration 3500:0.17223759738934277 || Accuracy: 95.49264705882354\n",
      "Loss after a iteration 3600:0.17016724861385651 || Accuracy: 95.59558823529412\n",
      "Loss after a iteration 3700:0.16951890141039738 || Accuracy: 95.625\n",
      "Loss after a iteration 3800:0.16622356713138683 || Accuracy: 95.66176470588236\n",
      "Loss after a iteration 3900:0.16478620619914744 || Accuracy: 95.73529411764706\n",
      "Loss after a iteration 4000:0.16282725034093018 || Accuracy: 95.81617647058823\n",
      "Loss after a iteration 4100:0.16117551492135 || Accuracy: 95.88970588235294\n",
      "Loss after a iteration 4200:0.16221456930354072 || Accuracy: 95.86764705882352\n",
      "Loss after a iteration 4300:0.15759647239251076 || Accuracy: 96.0220588235294\n",
      "Loss after a iteration 4400:0.1577979481574926 || Accuracy: 96.05882352941177\n",
      "Loss after a iteration 4500:0.15422336551413704 || Accuracy: 96.17647058823529\n",
      "Loss after a iteration 4600:0.1539642013490906 || Accuracy: 96.19852941176471\n",
      "Loss after a iteration 4700:0.15098716381858127 || Accuracy: 96.25\n",
      "Loss after a iteration 4800:0.15034622376012594 || Accuracy: 96.26470588235294\n",
      "Loss after a iteration 4900:0.1479556113661477 || Accuracy: 96.375\n",
      "Loss after a iteration 5000:0.14782043301906983 || Accuracy: 96.38235294117648\n",
      "Loss after a iteration 5100:0.1451115878068145 || Accuracy: 96.5220588235294\n",
      "Loss after a iteration 5200:0.14617332494071694 || Accuracy: 96.47058823529412\n",
      "Loss after a iteration 5300:0.14243252401091988 || Accuracy: 96.53676470588235\n",
      "Loss after a iteration 5400:0.14114893237153728 || Accuracy: 96.61029411764706\n",
      "Loss after a iteration 5500:0.14005834685534144 || Accuracy: 96.6029411764706\n",
      "Loss after a iteration 5600:0.13857847016372124 || Accuracy: 96.6764705882353\n",
      "Loss after a iteration 5700:0.13785694187752515 || Accuracy: 96.68382352941177\n",
      "Loss after a iteration 5800:0.13638278092847686 || Accuracy: 96.74264705882352\n",
      "Loss after a iteration 5900:0.1358174948877989 || Accuracy: 96.75735294117646\n",
      "Loss after a iteration 6000:0.13430041285317149 || Accuracy: 96.79411764705883\n",
      "Loss after a iteration 6100:0.13381749954973135 || Accuracy: 96.85294117647058\n",
      "Loss after a iteration 6200:0.13228565588310898 || Accuracy: 96.86029411764706\n",
      "Loss after a iteration 6300:0.13205892841858022 || Accuracy: 96.88970588235294\n",
      "Loss after a iteration 6400:0.1303900770838049 || Accuracy: 96.91176470588235\n",
      "Loss after a iteration 6500:0.13111047857998576 || Accuracy: 96.88235294117648\n",
      "Loss after a iteration 6600:0.12862975192139323 || Accuracy: 96.94117647058823\n",
      "Loss after a iteration 6700:0.1280857354672492 || Accuracy: 96.90441176470588\n",
      "Loss after a iteration 6800:0.12708158220115737 || Accuracy: 96.97058823529412\n",
      "Loss after a iteration 6900:0.12603196853748233 || Accuracy: 96.98529411764706\n",
      "Loss after a iteration 7000:0.12567632438440815 || Accuracy: 97.0\n",
      "Loss after a iteration 7100:0.12447626256281898 || Accuracy: 97.00735294117648\n",
      "Loss after a iteration 7200:0.12460405387699716 || Accuracy: 97.05147058823529\n",
      "Loss after a iteration 7300:0.12297917240512939 || Accuracy: 97.04411764705883\n",
      "Loss after a iteration 7400:0.3731200273712154 || Accuracy: 88.26470588235294\n",
      "Loss after a iteration 7500:0.12156076531402772 || Accuracy: 97.1029411764706\n",
      "Loss after a iteration 7600:0.12088321259408849 || Accuracy: 97.1470588235294\n",
      "Loss after a iteration 7700:0.12029793992528472 || Accuracy: 97.15441176470588\n",
      "Loss after a iteration 7800:0.11934710649275644 || Accuracy: 97.23529411764706\n",
      "Loss after a iteration 7900:0.3751853262205518 || Accuracy: 89.16176470588235\n",
      "Loss after a iteration 8000:0.11815085077581806 || Accuracy: 97.25\n",
      "Loss after a iteration 8100:0.117427003655826 || Accuracy: 97.25735294117646\n",
      "Loss after a iteration 8200:0.11722636636065437 || Accuracy: 97.27205882352942\n",
      "Loss after a iteration 8300:0.11624875893248442 || Accuracy: 97.29411764705883\n",
      "Loss after a iteration 8400:0.2578536453882357 || Accuracy: 91.125\n",
      "Loss after a iteration 8500:0.11519531410539126 || Accuracy: 97.33088235294117\n",
      "Loss after a iteration 8600:0.1145799062424446 || Accuracy: 97.33823529411765\n",
      "Loss after a iteration 8700:0.11450008672288638 || Accuracy: 97.33823529411765\n",
      "Loss after a iteration 8800:0.11366446826979658 || Accuracy: 97.36764705882352\n",
      "Loss after a iteration 8900:0.11494939621063084 || Accuracy: 97.25735294117646\n",
      "Loss after a iteration 9000:0.11279667057969762 || Accuracy: 97.375\n",
      "Loss after a iteration 9100:0.1126025297673923 || Accuracy: 97.38235294117648\n",
      "Loss after a iteration 9200:0.11206572033542092 || Accuracy: 97.36764705882352\n",
      "Loss after a iteration 9300:0.11143174903365939 || Accuracy: 97.41911764705883\n",
      "Loss after a iteration 9400:0.24412923178045332 || Accuracy: 91.33088235294117\n",
      "Loss after a iteration 9500:0.11074926389941869 || Accuracy: 97.41176470588235\n",
      "Loss after a iteration 9600:0.1102537526452794 || Accuracy: 97.43382352941177\n",
      "Loss after a iteration 9700:0.1105415416517878 || Accuracy: 97.41911764705883\n",
      "Loss after a iteration 9800:0.10951877375268808 || Accuracy: 97.43382352941177\n",
      "Loss after a iteration 9900:0.1110880680372813 || Accuracy: 97.44117647058823\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model  = Classifier(1024, [32,32, 10])\n",
    "model.forward_pass(X_train)\n",
    "loss = model.compute_loss_with_l2(model.output3_act, y_train)\n",
    "model.backward_pass_with_l2(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baaed3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c876e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.81698997e-05, 8.86685926e-04, 8.97632376e-04, 7.71747669e-01,\n",
       "       9.59224063e-04, 1.45842385e-02, 1.69192944e-01, 1.33229704e-02,\n",
       "       2.67895055e-06, 2.83577872e-02])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = model.predict(X_test)\n",
    "pr[0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63beb148",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpr_1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "pr_1[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1023aade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10941    6\n",
       "5250     3\n",
       "10292    6\n",
       "2266     1\n",
       "6398     3\n",
       "        ..\n",
       "4706     2\n",
       "8404     4\n",
       "11114    6\n",
       "7877     4\n",
       "6188     3\n",
       "Name: character, Length: 3400, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0cfc35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexs = np.arange(0, 100) * 100\n",
    "value = [x * 100 for x in model.loss_list]\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.title(\"Training Loss of the Model\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(indexs,value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d462ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model  = Classifier(1024, [32,16, 10])\n",
    "# model.forward_pass(X_train)\n",
    "# loss = model.compute_loss_with_l2(model.output3_act, y_train)\n",
    "# model.backward_pass(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "759f6c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after a iteration 0:2.302677164824908 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 100:2.3025389759383508 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 200:2.302351830029192 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 300:2.3017235407476075 || Accuracy: 9.88970588235294\n",
      "Loss after a iteration 400:2.2929413144350352 || Accuracy: 21.404411764705884\n",
      "Loss after a iteration 500:1.6143845966005945 || Accuracy: 29.772058823529413\n",
      "Loss after a iteration 600:1.423897904104247 || Accuracy: 41.61764705882353\n",
      "Loss after a iteration 700:0.8854916359191214 || Accuracy: 66.31617647058825\n",
      "Loss after a iteration 800:0.6372958570952105 || Accuracy: 76.52941176470588\n",
      "Loss after a iteration 900:0.5454960065193428 || Accuracy: 79.02941176470588\n",
      "Loss after a iteration 1000:0.5032702979940298 || Accuracy: 80.83088235294117\n",
      "Loss after a iteration 1100:0.47472469876328915 || Accuracy: 83.41911764705883\n",
      "Loss after a iteration 1200:0.43057262951013375 || Accuracy: 86.66176470588235\n",
      "Loss after a iteration 1300:0.3828469975821947 || Accuracy: 88.78676470588235\n",
      "Loss after a iteration 1400:0.35975827185091636 || Accuracy: 89.40441176470588\n",
      "Loss after a iteration 1500:0.3470982703674689 || Accuracy: 89.79411764705883\n",
      "Loss after a iteration 1600:0.33681875953964996 || Accuracy: 90.13970588235294\n",
      "Loss after a iteration 1700:0.3279748757707646 || Accuracy: 90.4264705882353\n",
      "Loss after a iteration 1800:0.31908318847981276 || Accuracy: 90.81617647058823\n",
      "Loss after a iteration 1900:0.30989515146194346 || Accuracy: 91.05882352941177\n",
      "Loss after a iteration 2000:0.29929196663209734 || Accuracy: 91.54411764705883\n",
      "Loss after a iteration 2100:0.2874617624111387 || Accuracy: 92.07352941176471\n",
      "Loss after a iteration 2200:0.2763098060414592 || Accuracy: 92.36764705882354\n",
      "Loss after a iteration 2300:0.26694142469572546 || Accuracy: 92.63970588235294\n",
      "Loss after a iteration 2400:0.2587586295641177 || Accuracy: 92.84558823529412\n",
      "Loss after a iteration 2500:0.2517297910854554 || Accuracy: 93.125\n",
      "Loss after a iteration 2600:0.244999777925549 || Accuracy: 93.32352941176471\n",
      "Loss after a iteration 2700:0.23850967340352935 || Accuracy: 93.5514705882353\n",
      "Loss after a iteration 2800:0.23275451897443966 || Accuracy: 93.79411764705883\n",
      "Loss after a iteration 2900:0.22869561034384447 || Accuracy: 93.86764705882354\n",
      "Loss after a iteration 3000:0.22802265796044383 || Accuracy: 93.90441176470588\n",
      "Loss after a iteration 3100:0.2405705075244186 || Accuracy: 93.15441176470588\n",
      "Loss after a iteration 3200:0.21092529334526344 || Accuracy: 94.38970588235294\n",
      "Loss after a iteration 3300:0.2079088401130079 || Accuracy: 94.4779411764706\n",
      "Loss after a iteration 3400:0.2053395217460258 || Accuracy: 94.5735294117647\n",
      "Loss after a iteration 3500:0.20301777959421863 || Accuracy: 94.61764705882352\n",
      "Loss after a iteration 3600:0.20143485759737093 || Accuracy: 94.63970588235294\n",
      "Loss after a iteration 3700:0.20091197534208002 || Accuracy: 94.69852941176471\n",
      "Loss after a iteration 3800:0.32679981255391527 || Accuracy: 88.41176470588236\n",
      "Loss after a iteration 3900:0.19435445212797603 || Accuracy: 94.91176470588235\n",
      "Loss after a iteration 4000:0.19266035080626032 || Accuracy: 95.0220588235294\n",
      "Loss after a iteration 4100:0.1913428537325238 || Accuracy: 95.05882352941177\n",
      "Loss after a iteration 4200:0.19036458884939508 || Accuracy: 95.0735294117647\n",
      "Loss after a iteration 4300:0.3695286788519291 || Accuracy: 87.58088235294117\n",
      "Loss after a iteration 4400:0.1862380149707637 || Accuracy: 95.23529411764706\n",
      "Loss after a iteration 4500:0.18453319062073648 || Accuracy: 95.27205882352942\n",
      "Loss after a iteration 4600:0.18334981885411586 || Accuracy: 95.32352941176471\n",
      "Loss after a iteration 4700:0.18390251001814817 || Accuracy: 95.31617647058823\n",
      "Loss after a iteration 4800:0.18008765864575782 || Accuracy: 95.36029411764706\n",
      "Loss after a iteration 4900:0.17852427084990227 || Accuracy: 95.44117647058825\n",
      "Loss after a iteration 5000:0.17736345961969846 || Accuracy: 95.4779411764706\n",
      "Loss after a iteration 5100:0.17716972691344401 || Accuracy: 95.5\n",
      "Loss after a iteration 5200:0.18398154016721738 || Accuracy: 94.79411764705883\n",
      "Loss after a iteration 5300:0.17301654951488807 || Accuracy: 95.6029411764706\n",
      "Loss after a iteration 5400:0.17201830811080654 || Accuracy: 95.63970588235294\n",
      "Loss after a iteration 5500:0.17138867683574902 || Accuracy: 95.67647058823529\n",
      "Loss after a iteration 5600:0.30184220202294443 || Accuracy: 89.01470588235294\n",
      "Loss after a iteration 5700:0.16848475554092388 || Accuracy: 95.69117647058823\n",
      "Loss after a iteration 5800:0.16774606960522756 || Accuracy: 95.75\n",
      "Loss after a iteration 5900:0.1673255313274211 || Accuracy: 95.78676470588235\n"
     ]
    }
   ],
   "source": [
    "model  = Classifier(1024, [32,32, 10])\n",
    "model.forward_pass(X_train)\n",
    "loss = model.compute_loss_with_l2(model.output3_act, y_train)\n",
    "model.backward_pass_with_l2(y_train, iteration = 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a80cde9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "model.save_model(f'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8268bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model: 88.17647058823529\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "y_acc = np.mean((y_test == y_test_pred))\n",
    "print(f'Test Accuracy of the model: {y_acc * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ffe91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 6, ..., 6, 4, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7892a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'1': model.weights1, '2': model.weights2, '3': model.weights3, \n",
    "           'b1':model.biases1,'b2':model.biases1,'b3':model.biases1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cbcf294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'base_model_weights_88.pkl'\n",
    "pickle.dump(weights, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c00ff0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'base_model_100.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daecd9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 2 6 ... 6 4 3]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(X_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1997142e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6402f6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afb27453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "# foo = Image.open('dataset/Test/digit_0/103277.png')  # My image is a 200x374 jpeg that is 102kb large\n",
    "foo = Image.open('number-5.png')\n",
    "foo= foo.convert('L')\n",
    "foo = foo.resize((32,32))\n",
    "# print(foo.size)  # (200, 374)\n",
    "image = np.array(foo)\n",
    "\n",
    "image = image.reshape(-1)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16ba2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Image.fromarray(image)\n",
    "      \n",
    "    # saving the final output \n",
    "    # as a PNG file\n",
    "data.save('gfg_dummy_pic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13f74b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastapi import FastAPI, File\n",
    "# from fastapi.middleware.cors import CORSMiddleware\n",
    "# from PIL import Image\n",
    "# import io\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import uvicorn\n",
    "# # import Classifier\n",
    "\n",
    "# app = FastAPI()\n",
    "# origins = [\n",
    "#     'http://localhost:8000',\n",
    "# ]\n",
    "# model = Classifier(1024, [32,32,10])\n",
    "# filename = 'base_model.pkl'\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# # print(loaded_model.weights1)\n",
    "# result = loaded_model.predict(X_test)\n",
    "\n",
    "# @app.get(\"/\")\n",
    "# async def root():\n",
    "#     return {\"message\": \"Wrong Method\"}\n",
    "\n",
    "# @app.post(\"/image\")\n",
    "# async def upload(file: bytes = File(...)):\n",
    "#     print(result)\n",
    "#     image = Image.open(io.BytesIO(file))\n",
    "# #     image.show()\n",
    "#     image = np.array(image)\n",
    "# #     image = image.resize((32, 32))\n",
    "# #     image = image.reshape(-1,)\n",
    "#     print(image.shape)\n",
    "#     # result = model.predict(image)\n",
    "#     print(\"The result is :\", result)\n",
    "#     return {\"Upload Status\": \"Complete\"}\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     config = uvicorn.Config(app)\n",
    "#     server = uvicorn.Server(config)\n",
    "#     await server.serve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc7772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
